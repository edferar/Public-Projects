{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "12188207",
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2025-10-24T20:20:57.294238Z",
          "iopub.status.busy": "2025-10-24T20:20:57.293457Z",
          "iopub.status.idle": "2025-10-24T20:20:57.302473Z",
          "shell.execute_reply": "2025-10-24T20:20:57.301296Z"
        },
        "id": "12188207",
        "outputId": "f75d2ee0-c1f4-43eb-ab5e-2c014354bfe4",
        "papermill": {
          "duration": 0.013511,
          "end_time": "2025-10-24T20:20:57.303990",
          "exception": false,
          "start_time": "2025-10-24T20:20:57.290479",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Um cuspidor esta nascendo!\n"
          ]
        }
      ],
      "source": [
        "print(\"Um cuspidor esta nascendo!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "7waazcN7jlrB",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7waazcN7jlrB",
        "outputId": "2ec5dd9b-bc67-466c-fc3a-e6d283024bba"
      },
      "outputs": [],
      "source": [
        "!pip install llama-index-readers-wikipedia -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "nilEBfU7_3ao",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nilEBfU7_3ao",
        "outputId": "a1918e88-5cc7-48dd-ad02-0296eb4afb63"
      },
      "outputs": [],
      "source": [
        "!pip install gradio duckdb duckdb-engine pandas unidecode --quiet\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "CSxx8LkUhmdG",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CSxx8LkUhmdG",
        "outputId": "825f9729-ee98-4f5d-ba0a-f58691300835"
      },
      "outputs": [],
      "source": [
        "!pip install llama-index llama-index-experimental llama-index-llms-groq -q"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "scwa3Frgg7jW",
      "metadata": {
        "id": "scwa3Frgg7jW"
      },
      "source": [
        "# Como Obter e Usar a API Key da Groq\n",
        "\n",
        "## 1. Criar Conta ou Fazer Login\n",
        "- Acesse [Groq Console](https://console.groq.com/login) e crie uma conta ou faça login se já possuir.\n",
        "\n",
        "## 2. Navegar até a Seção de API Keys\n",
        "- No painel da sua conta, vá até a página de [API Keys](https://console.groq.com/keys).\n",
        "\n",
        "## 3. Criar uma Nova API Key\n",
        "- Clique em **\"Create API Key\"**.\n",
        "- Dê um nome descritivo à chave (por exemplo: `Colab Integration`) e confirme a criação.\n",
        "\n",
        "## 4. Copiar a API Key\n",
        "- Após a criação, copie a API key exibida.\n",
        "- **Atenção:** Essa será a única vez que a chave será mostrada. Guarde-a em um local seguro.\n",
        "\n",
        "## 5. Configurar a Chave no Colab\n",
        "- **Boa prática:** Não coloque a chave diretamente no código. Em vez disso, use **Colab Secrets** ou variáveis de ambiente.\n",
        "\n",
        "Exemplo usando variável de ambiente:\n",
        "\n",
        "```python\n",
        "import os\n",
        "\n",
        "# Defina a variável de ambiente\n",
        "os.environ[\"GROQ_API_KEY\"] = \"sua-api-key-aqui\"\n",
        "\n",
        "#ou ustilizando secret\n",
        "from google.colab import userdata\n",
        "os.environ[\"GROQ_API_KEY\"] = userdata.get('GROQ_API_KEY')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "wVV7iHW7iBDk",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wVV7iHW7iBDk",
        "outputId": "149d2328-7648-43aa-d344-133546e45209"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Databases anexados:\n",
            "[('tb_bronze_escolas_gramame_geisel',)]\n",
            "['tb_bronze_escolas_gramame_geisel']\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "os.environ[\"GROQ_API_KEY\"] = userdata.get('GROQ_API_KEY')\n",
        "\n",
        "import duckdb\n",
        "from llama_index.llms.groq import Groq\n",
        "from sqlalchemy import create_engine, text\n",
        "\n",
        "\n",
        "\n",
        "engine = create_engine(\"duckdb:///:memory:\")\n",
        "ducklake_db = \"spitter_ducklake\"\n",
        "path = \"/tmp/dklq_spitter_ducklake\"\n",
        "\n",
        "with engine.connect() as con:\n",
        "    con.exec_driver_sql(\"INSTALL 'ducklake';\")\n",
        "    con.exec_driver_sql(\"LOAD 'ducklake';\")\n",
        "    con.exec_driver_sql(f\"\"\"ATTACH 'ducklake:metadata.ducklake' AS {ducklake_db} (DATA_PATH '{path}');\"\"\")\n",
        "    con.exec_driver_sql(f\"USE {ducklake_db}.bronze;\")\n",
        "    print(\"Databases anexados:\")\n",
        "    result = con.exec_driver_sql(f\"\"\"SHOW TABLES;\"\"\").fetchall()\n",
        "\n",
        "    print(result)\n",
        "    tables = [i[0] for i in result]\n",
        "    print(tables)\n",
        "\n",
        "    con.commit()\n",
        "\n",
        "# con = duckdb.connect(database=':memory:')\n",
        "# con.execute(f\"\"\"ATTACH 'ducklake:metadata.ducklake' AS {ducklake_db} (DATA_PATH '{path}');\"\"\")\n",
        "\n",
        "# #con.execute(\"SHOW tables;\").fetchall()\n",
        "# con.execute(f\"\"\"SELECT\n",
        "#     database_name,\n",
        "#     schema_name,\n",
        "#     table_name,\n",
        "#     temporary\n",
        "# FROM\n",
        "#     duckdb_tables\n",
        "# WHERE database_name= '{ducklake_db}';\"\"\").fetchall()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#con.execute(f\"SHOW TABLES FROM spitter_ducklake.duckdb;\").fetchall()\n",
        "#con.execute(\"USE spitter_ducklake.bronze;\")\n",
        "\n",
        "from llama_index.core import SQLDatabase\n",
        "from llama_index.core.query_engine import NLSQLTableQueryEngine\n",
        "from llama_index.core import Settings\n",
        "\n",
        "embed_model = Groq(model='llama-3.3-70b-versatile', api_key=os.environ.get(\"GROQ_API_KEY\"))\n",
        "\n",
        "sql_database = SQLDatabase(engine, include_tables=tables)\n",
        "query_engine = NLSQLTableQueryEngine(sql_database,embed_model=embed_model)\n",
        "#index = SQLStructStoreIndex(sql_database=db, include_tables=tables)\n",
        "#with engine.connect() as con:\n",
        "# print(con.execute(text(f\"\"\"SELECT * FROM spitter_ducklake.bronze.tb_bronze_escolas_gramame_geisel \"\"\")).fetchall())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "x68_uXWeiepn",
      "metadata": {
        "id": "x68_uXWeiepn"
      },
      "outputs": [],
      "source": [
        "from llama_index.core import Settings\n",
        "from llama_index.core import PromptTemplate\n",
        "\n",
        "Settings.llm = Groq(model='llama-3.3-70b-versatile', api_key=os.environ.get(\"GROQ_API_KEY\"))\n",
        "\n",
        "def get_table_statistcs(table, layer):\n",
        "    ducklake_db = \"spitter_ducklake\"\n",
        "    path = \"/tmp/dklq_spitter_ducklake\"\n",
        "    with duckdb.connect(database=':memory:') as con:\n",
        "      con.execute(f\"\"\"ATTACH 'ducklake:metadata.ducklake' AS {ducklake_db} (DATA_PATH '{path}');\"\"\")\n",
        "      con.execute(f\"USE {ducklake_db}.{layer};\")\n",
        "      desc = con.execute(f\"\"\"DESCRIBE FROM {table}\"\"\").fetchall()\n",
        "      cols = \",\".join([f'\"{row[0]}\"' for row in desc])\n",
        "      ref_query = f\"SELECT {cols} FROM {table}\"\n",
        "\n",
        "      desc_str = \"\\n\".join([f\"{col}: {dtype}\" for col, dtype, *_ in desc])\n",
        "      sample_df = con.execute(ref_query).fetchdf().head(10)\n",
        "      sample_df = sample_df.apply(lambda col: col.astype(str).str.slice(0, 50) if col.dtype == \"object\" else col)\n",
        "      sample_text = sample_df.to_string(index=False)\n",
        "\n",
        "\n",
        "    return desc_str, sample_text, ref_query\n",
        "\n",
        "\n",
        "def generate_sql(query, table, layer, last_query=False):\n",
        "    llm = Settings.llm\n",
        "\n",
        "    schema_table, sample_table,ref_query = get_table_statistcs(table, layer)\n",
        "    ref_query = last_query if last_query else ref_query\n",
        "    \"\"\"\"\n",
        "        Gere a consulta com base nas colunas da tabela.\\n\n",
        "        Modifique apenas os campos solicitados; todas as demais partes da query devem permanecer iguais.\\n\n",
        "        Caso solicitado, voce devera remover campos da query e desfazer alteracões.\\n\n",
        "        A query final deve ser uma expressão SQL válida e executável em SQL ANSI.\\n\n",
        "        Retorne apenas a query, sem explicações, comentários ou texto adicional, sem aspas.\\n\n",
        "\n",
        "    \"\"\"\n",
        "    prompt = (\n",
        "        \"Você está trabalhando com uma tabela chamada {table} SQL presente no duckdb.\\n\"\n",
        "        \"Descrição:\\n\"\n",
        "        \"{schema_table}\\n\\n\"\n",
        "        \"Algumas linhas da tabela\\n\"\n",
        "        \"{sample_table}\\n\\n\"\n",
        "\n",
        "        \"Query atual:\\n\"\n",
        "        \"{last_query}\\n\\n\"\n",
        "\n",
        "        \"Nova instrução:\\n\"\n",
        "        \"{query}\\n\\n\"\n",
        "\n",
        "        \"Gere uma **nova query SQL** baseada na query atual, alterando apenas o necessário.\\n\"\n",
        "        \"A query final deve ser executável em SQL ANSI.\\n\"\n",
        "        \"Retorne apenas a query, sem aspas ou complemento.\\n\")\n",
        "\n",
        "\n",
        "    sql_prompt = PromptTemplate(prompt).partial_format(\n",
        "        schema_table=schema_table,\n",
        "        table=table,\n",
        "        sample_table=sample_table,\n",
        "        query=query,\n",
        "        last_query = last_query )\n",
        "\n",
        "    sql_query = llm.predict(sql_prompt)\n",
        "    #response = llm.complete(sql_query_response).text\n",
        "\n",
        "\n",
        "    return sql_query\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "table = \"tb_bronze_escolas_gramame_geisel\"\n",
        "layer=\"bronze\"\n",
        "query_gen = False\n",
        "        #Query base:\\n\n",
        "        #{last_query}\\n\\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "id": "ity4USVqfivO",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ity4USVqfivO",
        "outputId": "283cb949-4d58-4322-a931-7fb96336d0f0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- QUERY SQL GERADA ---\n",
            "SELECT UPPER(bairro) AS bairro, LOWER(escola) AS escola, fonte FROM tb_bronze_escolas_gramame_geisel\n"
          ]
        }
      ],
      "source": [
        "query = \"Realize a conversao na coluna escola para minusculo, e mantenha as demais como estao\"\n",
        "query_gen = generate_sql(query, table, layer, last_query=query_gen)\n",
        "\n",
        "print(\"\\n--- QUERY SQL GERADA ---\")\n",
        "print(query_gen)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "xvnA39l5fh8A",
      "metadata": {
        "id": "xvnA39l5fh8A"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "mp1gCpwvlQ5m",
      "metadata": {
        "id": "mp1gCpwvlQ5m"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "YUJttku7PY-t",
      "metadata": {
        "id": "YUJttku7PY-t"
      },
      "outputs": [],
      "source": [
        "from unidecode import unidecode\n",
        "import traceback\n",
        "import os\n",
        "\n",
        "import re\n",
        "\n",
        "class SpitterDucklakeOperator():\n",
        "    def __init__(self,con,  path=None):\n",
        "\n",
        "      self.ducklake_db = \"spitter_ducklake\"\n",
        "      self.path_prefix = os.environ.get(\"TMP\").replace(\"\\\\\",\"/\") if os.name == \"nt\" else \"/tmp\"\n",
        "      self.path = path if path else f\"{self.path_prefix}/dklq_{self.ducklake_db}\"\n",
        "      self.con = con\n",
        "      self.init_ducklake()\n",
        "\n",
        "\n",
        "    def init_ducklake(self):\n",
        "      try:\n",
        "        #con = duckdb.connect(database=':memory:')\n",
        "        self.con.execute(\"INSTALL ducklake;\")\n",
        "        self.con.execute(f\"DETACH DATABASE IF EXISTS {self.ducklake_db};\")\n",
        "        self.con.execute(f\"ATTACH 'ducklake:metadata.ducklake' AS {self.ducklake_db} (DATA_PATH '{self.path}');\")\n",
        "        #return con\n",
        "      except Exception as e:\n",
        "        raise e\n",
        "\n",
        "    def table_exist(self, table):\n",
        "      try:\n",
        "        self.con.execute(f\"SELECT * FROM {table} LIMIT 0\")\n",
        "        return True\n",
        "      except Exception as e:\n",
        "        return False\n",
        "\n",
        "    def normalize_name(self, col):\n",
        "      col = unidecode(col).lower().strip()\n",
        "      col = re.sub(r'[^a-z0-9_]', '_', col)\n",
        "      col = re.sub(r'_+', '_', col)\n",
        "      return col.strip('_').encode(\"utf-8\", errors=\"ignore\").decode(\"utf-8\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def create_or_replace_table(self, source_table_name, output_table_name, layer, primary_key=False):\n",
        "      try:\n",
        "        self.con.execute(f\"CREATE SCHEMA IF NOT EXISTS {self.ducklake_db}.{layer}\")\n",
        "\n",
        "        instruction_sql = ','.join([\"{0} {1} {2}\".format(\n",
        "                                                          self.normalize_name(row[0]),\n",
        "                                                          row[1],\n",
        "                                                          \"\" if row[0] != primary_key else 'PRIMARY KEY'\n",
        "                                                        ) for row in self.con.execute(f\"DESCRIBE FROM {source_table_name}\").fetchall()\n",
        "                                  ]\n",
        "                                    )\n",
        "\n",
        "        self.con.execute(f\"\"\"CREATE OR REPLACE TABLE {self.ducklake_db}.{layer}.{output_table_name} ({instruction_sql})\"\"\")\n",
        "\n",
        "        return True, \"success\"\n",
        "      except Exception as e:\n",
        "        return False, f\"{e} -> {traceback.format_exc()}\"\n",
        "\n",
        "    def insert_table(self, source_table_name, output_table_name, layer,op_mode, primary_key=False):\n",
        "      try:\n",
        "        if not self.table_exist(f\"{self.ducklake_db}.{layer}.{output_table_name}\") or op_mode == \"overwrite\":\n",
        "            self.create_or_replace_table(source_table_name, output_table_name, layer, primary_key)\n",
        "\n",
        "        if primary_key:\n",
        "          self.con.execute(f\"INSERT OR REPLACE INTO {self.ducklake_db}.{layer}.{output_table_name} SELECT * FROM {source_table_name}\")\n",
        "        else:\n",
        "          self.con.execute(f\"INSERT INTO {self.ducklake_db}.{layer}.{output_table_name} SELECT * FROM {source_table_name}\")\n",
        "\n",
        "        return True, \"success\"\n",
        "      except Exception as e:\n",
        "        return False, f\"{e} -> {traceback.format_exc()}\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "-8fKAy_MFPm9",
      "metadata": {
        "id": "-8fKAy_MFPm9"
      },
      "outputs": [],
      "source": [
        "#csv operations\n",
        "import duckdb\n",
        "import pandas as pd\n",
        "import traceback\n",
        "\n",
        "class SpitterOperator():\n",
        "    def __init__(self, file):\n",
        "        self.df = pd.DataFrame()\n",
        "        self.primary_key = \"\"\n",
        "        self.cols = []\n",
        "        self.con = duckdb.connect(database=':memory:')\n",
        "        self.dklq = SpitterDucklakeOperator(self.con)\n",
        "        self.table_name = \"\"\n",
        "        self.op_mode = \"\"\n",
        "        if file is not None:\n",
        "            self.load_bronze(file)\n",
        "        else:\n",
        "            return \"Envie um file CSV.\"\n",
        "\n",
        "    def preview_bronze(self):\n",
        "        norm_cols = \",\".join([f'\"{col}\" AS {self.dklq.normalize_name(col)}' for col in self.cols])\n",
        "        preview_df = self.con.execute(f\"\"\"\n",
        "          SELECT {norm_cols} FROM tmp_{self.table_name} LIMIT 10\n",
        "        \"\"\").fetchdf()\n",
        "        return preview_df\n",
        "\n",
        "    def set_primary_key(self, column_name):\n",
        "        if column_name in self.df.columns:\n",
        "            self.primary_key = column_name\n",
        "\n",
        "    def set_table_op_mode(self, op_mode):\n",
        "        self.op_mode = op_mode\n",
        "\n",
        "    def persist_table_on_dklq(self, layer):\n",
        "        result = self.dklq.insert_table(f\"tmp_{self.table_name}\", f\"tb_{layer}_{self.table_name}\", layer, self.op_mode, self.primary_key)\n",
        "        if not result[0]:\n",
        "          raise Exception(result[1])\n",
        "\n",
        "\n",
        "    def load_bronze(self,file):\n",
        "\n",
        "        try:\n",
        "\n",
        "          self.table_name = self.dklq.normalize_name(file.name.replace(\"\\\\\", \"/\").split(\"/\")[-1].split(\".\")[0])\n",
        "          self.con.execute(f\"\"\"\n",
        "              CREATE TEMPORARY TABLE tmp_{self.table_name} AS\n",
        "              SELECT * FROM read_csv_auto('{file.name}', header=True)\n",
        "          \"\"\")\n",
        "          self.cols = [row[0] for row in self.con.execute(f\"DESCRIBE tmp_{self.table_name}\").fetchall()]\n",
        "        except Exception as e:\n",
        "          raise (f\"{e} -> {traceback.format_exc()}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "PfmR2fRj_6XA",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 680
        },
        "id": "PfmR2fRj_6XA",
        "outputId": "8d6ca330-8d49-4e5c-fd2b-616a815f9d16"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://28280389c75a1f11f4.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"https://28280389c75a1f11f4.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7860 <> https://28280389c75a1f11f4.gradio.live\n"
          ]
        },
        {
          "data": {
            "text/plain": []
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import gradio as gr\n",
        "\n",
        "def init_file_operator(file):\n",
        "    spitter_operator = SpitterOperator(file)\n",
        "    return spitter_operator, \"bronze\"\n",
        "\n",
        "def preview_bronze(spitter_operator):\n",
        "    return spitter_operator.preview_bronze()\n",
        "\n",
        "def set_pk_column(spitter_operator, pk_column):\n",
        "    if spitter_operator is not None:\n",
        "        spitter_operator.set_primary_key(pk_column)\n",
        "    return spitter_operator\n",
        "\n",
        "#button options\n",
        "def set_pk_chk_visibility(spitter_operator, checkbox_value):\n",
        "    if checkbox_value:\n",
        "        return gr.update(interactive=True, visible=True,choices=spitter_operator.cols)\n",
        "    else:\n",
        "        return gr.update(interactive=False, visible=False)\n",
        "\n",
        "def set_op_chk_visibility(spitter_operator, layer):\n",
        "    choices = [\"append\", \"overwrite\"] if layer == \"bronze\" else [\"overwrite\",\"upsert\"]\n",
        "    return gr.update(interactive=True, visible=True, choices= choices)\n",
        "\n",
        "\n",
        "def set_table_op_mode_btn(spitter_operator, op_mode):\n",
        "  spitter_operator.set_table_op_mode(op_mode)\n",
        "  return f\"Commit - table -> {spitter_operator.table_name} | op_mode -> {op_mode}\", True\n",
        "\n",
        "def publish_bronze_table(spitter_operator, commit_state, layer):\n",
        "  if commit_state:\n",
        "    spitter_operator.persist_table_on_dklq(layer)\n",
        "    return \"sucess\"\n",
        "  else:\n",
        "    return \"Error. Please check your settings!\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "with gr.Blocks(title=\"# Arquitetura Medalhão - Data Spitter - CSV - multi Reads\") as spitter_demo:\n",
        "    gr.Markdown(\"# Arquitetura Medalhão (Bronze / Silver / Gold)\")\n",
        "    gr.Markdown(\"## Spitter Data Lakehouse Explorer\")\n",
        "    gr.Markdown(\"## Leia seus dados, configure as operacoes, e maos a obra. Apresentamos suporte a cargas incrementais e de sobrescrita\")\n",
        "    gr.Markdown(\"As tabelas criadas utilizarao o nome do arquivo como referencia\")\n",
        "    st_spitter_operator = gr.State(None)\n",
        "    st_layer = gr.State(\"\")\n",
        "\n",
        "    #BronzeLayer\n",
        "    with gr.Tab(\"Bronze Layer\"):\n",
        "        gr.Markdown(\"### Upload dos dados brutos\")\n",
        "        st_choices = gr.State([])\n",
        "        st_commit_bronze = gr.State(False)\n",
        "\n",
        "        csv_bronze = gr.File(label=\"Selecione um CSV\",file_count=\"single\", type=\"filepath\")\n",
        "        csv_bronze.upload(init_file_operator, inputs=csv_bronze, outputs=[st_spitter_operator,st_layer])\n",
        "\n",
        "\n",
        "        bronze_btn = gr.Button(\"Preview Bronze\")\n",
        "        bronze_table = gr.DataFrame(label=\"Bronze Data\")\n",
        "        bronze_btn.click(preview_bronze, inputs=st_spitter_operator, outputs=bronze_table)\n",
        "\n",
        "        gr.Markdown(\"### Limpeza dos dados brutos\")\n",
        "\n",
        "\n",
        "        op_dropdown = gr.Dropdown(label=\"Select the table operaration mode (required)\", choices=[], interactive=False, visible=False)\n",
        "        st_spitter_operator.change(set_op_chk_visibility,inputs=[st_spitter_operator, st_layer],outputs=op_dropdown)\n",
        "\n",
        "        output_text = gr.Markdown(\"\")\n",
        "        op_dropdown.change(set_table_op_mode_btn, inputs=[st_spitter_operator, op_dropdown], outputs=[output_text, st_commit_bronze])\n",
        "\n",
        "        alerta_md_component = gr.Markdown(\"\")\n",
        "        publish_bronze_btn = gr.Button(value=f\"Commit\", visible=True)\n",
        "        publish_bronze_btn.click(publish_bronze_table, inputs=[st_spitter_operator, st_commit_bronze, st_layer], outputs=alerta_md_component)\n",
        "\n",
        "    #SilverLayer\n",
        "    with gr.Tab(\"Camada Silver\"):\n",
        "\n",
        "        pk_checkbox = gr.Checkbox(label=\"Does the table have a primary key?\", value=False)\n",
        "        pk_dropdown = gr.Dropdown(label=\"Select the primary key\", choices=[], interactive=False, visible=False)\n",
        "        pk_checkbox.change(set_pk_chk_visibility, inputs=[st_spitter_operator, pk_checkbox], outputs=pk_dropdown)\n",
        "        pk_dropdown.change(set_pk_column, inputs=[st_spitter_operator, pk_dropdown], outputs=st_spitter_operator)\n",
        "\n",
        "\n",
        "\n",
        "spitter_demo.launch(debug=True)\n",
        "#spitter_demo.queue(show_error=True)\n",
        "#spitter_demo.launch(share=True)\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [],
      "dockerImageVersionId": 31153,
      "isGpuEnabled": false,
      "isInternetEnabled": false,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.10"
    },
    "papermill": {
      "default_parameters": {},
      "duration": 5.226134,
      "end_time": "2025-10-24T20:20:57.625124",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2025-10-24T20:20:52.398990",
      "version": "2.6.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
