{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "12188207",
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2025-10-24T20:20:57.294238Z",
          "iopub.status.busy": "2025-10-24T20:20:57.293457Z",
          "iopub.status.idle": "2025-10-24T20:20:57.302473Z",
          "shell.execute_reply": "2025-10-24T20:20:57.301296Z"
        },
        "id": "12188207",
        "outputId": "5281a581-a4ea-4479-a10c-2c3641acae8c",
        "papermill": {
          "duration": 0.013511,
          "end_time": "2025-10-24T20:20:57.303990",
          "exception": false,
          "start_time": "2025-10-24T20:20:57.290479",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Um cuspidor esta nascendo!\n"
          ]
        }
      ],
      "source": [
        "print(\"Um cuspidor esta nascendo!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "7waazcN7jlrB",
      "metadata": {
        "id": "7waazcN7jlrB"
      },
      "outputs": [],
      "source": [
        "!pip install llama-index-readers-wikipedia -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "nilEBfU7_3ao",
      "metadata": {
        "id": "nilEBfU7_3ao"
      },
      "outputs": [],
      "source": [
        "!pip install gradio duckdb duckdb-engine pandas unidecode --quiet\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "CSxx8LkUhmdG",
      "metadata": {
        "id": "CSxx8LkUhmdG"
      },
      "outputs": [],
      "source": [
        "!pip install llama-index llama-index-experimental llama-index-llms-groq -q"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "scwa3Frgg7jW",
      "metadata": {
        "id": "scwa3Frgg7jW"
      },
      "source": [
        "# Como Obter e Usar a API Key da Groq\n",
        "\n",
        "## 1. Criar Conta ou Fazer Login\n",
        "- Acesse [Groq Console](https://console.groq.com/login) e crie uma conta ou faça login se já possuir.\n",
        "\n",
        "## 2. Navegar até a Seção de API Keys\n",
        "- No painel da sua conta, vá até a página de [API Keys](https://console.groq.com/keys).\n",
        "\n",
        "## 3. Criar uma Nova API Key\n",
        "- Clique em **\"Create API Key\"**.\n",
        "- Dê um nome descritivo à chave (por exemplo: `Colab Integration`) e confirme a criação.\n",
        "\n",
        "## 4. Copiar a API Key\n",
        "- Após a criação, copie a API key exibida.\n",
        "- **Atenção:** Essa será a única vez que a chave será mostrada. Guarde-a em um local seguro.\n",
        "\n",
        "## 5. Configurar a Chave no Colab\n",
        "- **Boa prática:** Não coloque a chave diretamente no código. Em vez disso, use **Colab Secrets** ou variáveis de ambiente.\n",
        "\n",
        "Exemplo usando variável de ambiente:\n",
        "\n",
        "```python\n",
        "import os\n",
        "\n",
        "# Defina a variável de ambiente\n",
        "os.environ[\"GROQ_API_KEY\"] = \"sua-api-key-aqui\"\n",
        "\n",
        "#ou ustilizando secret\n",
        "from google.colab import userdata\n",
        "os.environ[\"GROQ_API_KEY\"] = userdata.get('GROQ_API_KEY')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "os.environ[\"GROQ_API_KEY\"] = userdata.get('GROQ_API_KEY')"
      ],
      "metadata": {
        "id": "1ID-l-qMipNf"
      },
      "id": "1ID-l-qMipNf",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SpitterDucklakeEngines"
      ],
      "metadata": {
        "id": "K93B0UAEfBQc"
      },
      "id": "K93B0UAEfBQc"
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sqlalchemy import create_engine\n",
        "\n",
        "class SpitterDucklakeEngines():\n",
        "  @classmethod\n",
        "  def get_session_duckdb(self, ducklake_db, path, layer=False):\n",
        "    engine = create_engine(\"duckdb:///:memory:\")\n",
        "\n",
        "    with engine.connect() as con:\n",
        "      con.exec_driver_sql(\"INSTALL 'ducklake';\")\n",
        "      con.exec_driver_sql(\"LOAD 'ducklake';\")\n",
        "      #con.exec_driver_sql(f\"DETACH DATABASE IF EXISTS {ducklake_db};\")\n",
        "      con.exec_driver_sql(f\"\"\"ATTACH 'ducklake:metadata.ducklake' AS {ducklake_db} (DATA_PATH '{path}');\"\"\")\n",
        "\n",
        "      result = con.exec_driver_sql(f\"\"\"SHOW DATABASES;\"\"\").fetchall()\n",
        "      print(\"Databases anexados:\", [i[0] for i in result])\n",
        "      if layer:\n",
        "        con.exec_driver_sql(f\"CREATE SCHEMA IF NOT EXISTS {ducklake_db}.{layer}\")\n",
        "        con.exec_driver_sql(f\"USE {ducklake_db}.{layer};\")\n",
        "      else:\n",
        "        con.exec_driver_sql(f\"USE {ducklake_db};\")\n",
        "\n",
        "      result = con.exec_driver_sql(f\"\"\"SHOW TABLES;\"\"\").fetchall()\n",
        "\n",
        "      con.commit()\n",
        "\n",
        "    return engine\n",
        "\n",
        "\n",
        "  @classmethod\n",
        "  def get_tables(self, engine, ducklake_db, layer=False):\n",
        "    cond = f\"database_name= '{ducklake_db}'AND schema_name = '{layer}'\" if layer else f\"database_name= '{ducklake_db}'\"\n",
        "    with engine.connect() as con:\n",
        "      result = con.exec_driver_sql(f\"\"\"\n",
        "          SELECT table_name\n",
        "          FROM duckdb_tables\n",
        "          WHERE {cond}\n",
        "          ORDER BY table_name;\n",
        "          ;\"\"\").fetchall()\n",
        "    tables = [i[0] for i in result]\n",
        "\n",
        "    print(\"Tabelas identificadas:\", tables)\n",
        "    return tables\n",
        "\n",
        "  @classmethod\n",
        "  def dispose_connection(self, engine):\n",
        "    if engine:\n",
        "      engine.dispose()\n"
      ],
      "metadata": {
        "id": "B37g3AV-fD5x"
      },
      "id": "B37g3AV-fD5x",
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SpitterDucklakeAnalystOperator"
      ],
      "metadata": {
        "id": "yroh6bVCfIWT"
      },
      "id": "yroh6bVCfIWT"
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "from llama_index.llms.groq import Groq\n",
        "from llama_index.core import SQLDatabase\n",
        "from llama_index.core.query_engine import NLSQLTableQueryEngine\n",
        "from llama_index.core import Settings\n",
        "from llama_index.core import PromptTemplate\n",
        "\n",
        "class SpitterDucklakeAnalystOperator():\n",
        "  def __init__(self,engine, ducklake_db, path, groq_model='llama-3.3-70b-versatile'):\n",
        "    self.llm = Groq(model=groq_model, api_key=self.get_groq_environment())\n",
        "    self.ducklake_db = ducklake_db\n",
        "    self.path = path\n",
        "    self.engine = engine\n",
        "    self.query_engine = None\n",
        "\n",
        "\n",
        "  def get_groq_environment(self):\n",
        "    if not os.environ.get(\"GROQ_API_KEY\"):\n",
        "        raise ValueError(\"A chave GROQ_API_KEY não foi fornecida nem encontrada no ambiente.\")\n",
        "    return os.environ.get(\"GROQ_API_KEY\")\n",
        "\n",
        "  def get_query_engine(self, layer='silver', tables=[]):\n",
        "      tables = tables if tables else  self.engine_op.get_tables(self.engine, self.ducklake_db, layer)\n",
        "      sql_database = SQLDatabase(self.engine, include_tables=tables)\n",
        "\n",
        "      return NLSQLTableQueryEngine(sql_database, embed_model=self.llm)\n"
      ],
      "metadata": {
        "id": "xzZ6xbNKiqeg"
      },
      "id": "xzZ6xbNKiqeg",
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# tables = ['tb_bronze_escolas_gramame_geisel']\n",
        "# ducklake = \"spitter_ducklake\"\n",
        "# path = \"/tmp/dklq_spitter_ducklake\"\n",
        "# layer = \"bronze\"\n",
        "# op = SpitterDucklakeAnalystOperator()\n",
        "# query_engine = op.get_query_engine(ducklake, path, layer, tables)\n",
        "# query_engine.query(\"Qual bairro possui mais escolas?\")\n"
      ],
      "metadata": {
        "id": "ajJyeqf2vn6w"
      },
      "id": "ajJyeqf2vn6w",
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#op.close()"
      ],
      "metadata": {
        "id": "DPv_xCFSC8r4"
      },
      "id": "DPv_xCFSC8r4",
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SpitterDucklakeEngenieertOperator"
      ],
      "metadata": {
        "id": "H02_f2n923JV"
      },
      "id": "H02_f2n923JV"
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "id": "x68_uXWeiepn",
      "metadata": {
        "id": "x68_uXWeiepn"
      },
      "outputs": [],
      "source": [
        "from llama_index.core import Settings\n",
        "from llama_index.core import PromptTemplate\n",
        "\n",
        "class SpitterDucklakeEngenieertOperator():\n",
        "  def __init__(self, engine, ducklake_db, path, groq_model='llama-3.3-70b-versatile'):\n",
        "\n",
        "    self.ducklake_db = ducklake_db\n",
        "    self.path = path\n",
        "    self.query_engine = None\n",
        "    self.engine = engine\n",
        "    Settings.llm = Groq(model='llama-3.3-70b-versatile', api_key=self.get_groq_environment())\n",
        "\n",
        "\n",
        "  def get_groq_environment(self):\n",
        "    if not os.environ.get(\"GROQ_API_KEY\"):\n",
        "        raise ValueError(\"A chave GROQ_API_KEY não foi fornecida nem encontrada no ambiente.\")\n",
        "    return os.environ.get(\"GROQ_API_KEY\")\n",
        "\n",
        "  def get_table_statistcs(self, table):\n",
        "      with self.engine.connect() as con:\n",
        "        desc = con.exec_driver_sql(f\"\"\"DESCRIBE FROM {table}\"\"\").fetchall()\n",
        "        cols = \",\".join([f'\"{row[0]}\"' for row in desc])\n",
        "        ref_query = f\"SELECT {cols} FROM {table}\"\n",
        "\n",
        "        desc_str = \"\\n\".join([f\"{col}: {dtype}\" for col, dtype, *_ in desc])\n",
        "        sample_df = con.exec_driver_sql(ref_query).fetchall()\n",
        "        sample_df = pd.DataFrame(sample_df, columns=[row[0] for row in desc]).head(10)\n",
        "        sample_df = sample_df.apply(lambda col: col.astype(str).str.slice(0, 50) if col.dtype == \"object\" else col)\n",
        "        sample_text = sample_df.to_string(index=False)\n",
        "\n",
        "      return desc_str, sample_text, ref_query\n",
        "\n",
        "\n",
        "  def generate_sql(self, query, table, layer='bronze', last_query=False):\n",
        "      print(\"Insturacao recebida:\", query)\n",
        "      print(\"Query recebida:\", last_query)\n",
        "      llm = Settings.llm\n",
        "      schema_table, sample_table, ref_query = self.get_table_statistcs(table)\n",
        "      ref_query = last_query if last_query else ref_query\n",
        "      prompt = (\n",
        "          \"Você está trabalhando com uma tabela chamada {table} SQL presente no duckdb.\\n\"\n",
        "          \"Descrição:\\n\"\n",
        "          \"{schema_table}\\n\\n\"\n",
        "          \"Algumas linhas da tabela\\n\"\n",
        "          \"{sample_table}\\n\\n\"\n",
        "\n",
        "          \"Query atual:\\n\"\n",
        "          \"{last_query}\\n\\n\"\n",
        "\n",
        "          \"Nova instrução:\\n\"\n",
        "          \"{query}\\n\\n\"\n",
        "\n",
        "          \"A nova query deve utiilizar a atual como referencia, exceto pelas alterações explicitamente pedidas na nova instrução.\\n\"\n",
        "          \"Modifique somente o que for mencionado.\\n\"\n",
        "          \"Mantenha estrutura, filtros, joins, aliases e ordenações originais se não forem citados.\\n\"\n",
        "          \"Se for solicitado, você pode remover ou desfazer alterações anteriores.\\n\"\n",
        "          \"Somente se explicitamente indicado, ignore a query atual e gere uma nova query do zero.\\n\"\n",
        "          \"A query final deve ser executável em SQL ANSI.\\n\"\n",
        "          \"Retorne somente a query, sem aspas, comentários ou texto adicional.\\n\"\n",
        "          )\n",
        "\n",
        "\n",
        "      sql_prompt = PromptTemplate(prompt).partial_format(\n",
        "          schema_table=schema_table,\n",
        "          table=table,\n",
        "          sample_table=sample_table,\n",
        "          query=query,\n",
        "          last_query = last_query )\n",
        "\n",
        "      sql_query = llm.predict(sql_prompt)\n",
        "      print(\"Query gerada:\", sql_query)\n",
        "      return sql_query\n",
        "\n",
        "# table = \"tb_bronze_escolas_gramame_geisel\"\n",
        "# layer=\"bronze\"\n",
        "# query_gen = False\n",
        "# op = SpitterDucklakeEngenieertOperator()\n",
        "\n",
        "# ducklake = \"spitter_ducklake\"\n",
        "# path = \"/tmp/dklq_spitter_ducklake\"\n",
        "# layer = \"bronze\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "ity4USVqfivO",
      "metadata": {
        "id": "ity4USVqfivO"
      },
      "outputs": [],
      "source": [
        "# query = \"Inclua a coluna escola na query\"\n",
        "# query_gen = op.generate_sql(query, table, layer, ducklake, path, last_query=query_gen)\n",
        "# print(\"\\n--- QUERY SQL GERADA ---\")\n",
        "# print(query_gen)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#op.close()"
      ],
      "metadata": {
        "id": "sksCMEgfDlE8"
      },
      "id": "sksCMEgfDlE8",
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "xvnA39l5fh8A",
      "metadata": {
        "id": "xvnA39l5fh8A"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "mp1gCpwvlQ5m",
      "metadata": {
        "id": "mp1gCpwvlQ5m"
      },
      "source": [
        "## SpitterDucklakeOperator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "id": "YUJttku7PY-t",
      "metadata": {
        "id": "YUJttku7PY-t"
      },
      "outputs": [],
      "source": [
        "from unidecode import unidecode\n",
        "import traceback\n",
        "import os\n",
        "\n",
        "import re\n",
        "\n",
        "class SpitterDucklakeOperator():\n",
        "    def __init__(self, engine, ducklake_db, path=None):\n",
        "\n",
        "      self.ducklake_db = ducklake_db\n",
        "      self.engine = engine\n",
        "\n",
        "    def table_exist(self, table):\n",
        "      try:\n",
        "        with self.engine.connect() as con:\n",
        "          con.exec_driver_sql(f\"SELECT * FROM {table} LIMIT 0\")\n",
        "\n",
        "        return True\n",
        "      except Exception as e:\n",
        "        return False\n",
        "\n",
        "    def normalize_name(self, col):\n",
        "      col = unidecode(col).lower().strip()\n",
        "      col = re.sub(r'[^a-z0-9_]', '_', col)\n",
        "      col = re.sub(r'_+', '_', col)\n",
        "      return col.strip('_').encode(\"utf-8\", errors=\"ignore\").decode(\"utf-8\")\n",
        "\n",
        "    def create_or_replace_table(self, source_table_name, output_table_name, layer, primary_key=False):\n",
        "      try:\n",
        "        with self.engine.connect() as con:\n",
        "          instruction_sql = ','.join([\"{0} {1} {2}\".format(\n",
        "                                                            self.normalize_name(row[0]),\n",
        "                                                            row[1],\n",
        "                                                            \"\" if row[0] != primary_key else 'PRIMARY KEY'\n",
        "                                                          ) for row in con.exec_driver_sql(f\"DESCRIBE FROM {source_table_name}\").fetchall()\n",
        "                                    ]\n",
        "                                      )\n",
        "          con.exec_driver_sql(f\"CREATE SCHEMA IF NOT EXISTS {self.ducklake_db}.{layer}\")\n",
        "          con.exec_driver_sql(f\"\"\"CREATE OR REPLACE TABLE {self.ducklake_db}.{layer}.{output_table_name} ({instruction_sql})\"\"\")\n",
        "          con.commit()\n",
        "        return True, \"success\"\n",
        "      except Exception as e:\n",
        "        return False, f\"{e} -> {traceback.format_exc()}\"\n",
        "\n",
        "    def insert_table(self, source_table_name, output_table_name, layer,op_mode, primary_key=False):\n",
        "      try:\n",
        "        with self.engine.connect() as con:\n",
        "          if not self.table_exist(f\"{self.ducklake_db}.{layer}.{output_table_name}\") or op_mode == \"overwrite\":\n",
        "              self.create_or_replace_table(source_table_name, output_table_name, layer, primary_key)\n",
        "              con.commit()\n",
        "          if primary_key:\n",
        "            con.exec_driver_sql(f\"INSERT OR REPLACE INTO {self.ducklake_db}.{layer}.{output_table_name} SELECT * FROM {source_table_name}\")\n",
        "            con.commit()\n",
        "          else:\n",
        "            con.exec_driver_sql(f\"INSERT INTO {self.ducklake_db}.{layer}.{output_table_name} SELECT * FROM {source_table_name}\")\n",
        "            con.commit()\n",
        "        return True, \"success\"\n",
        "      except Exception as e:\n",
        "        return False, f\"{e} -> {traceback.format_exc()}\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SpitterOperator"
      ],
      "metadata": {
        "id": "QvFj_M4vMfa-"
      },
      "id": "QvFj_M4vMfa-"
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "id": "-8fKAy_MFPm9",
      "metadata": {
        "id": "-8fKAy_MFPm9"
      },
      "outputs": [],
      "source": [
        "#csv operations\n",
        "import duckdb\n",
        "import pandas as pd\n",
        "import traceback\n",
        "\n",
        "class SpitterOperator():\n",
        "    def __init__(self, content=False, ducklake_db=\"spitter_ducklake\", path=None):\n",
        "        self.df = pd.DataFrame()\n",
        "        self.primary_key = \"\"\n",
        "        self.cols = []\n",
        "        self.ducklake_db = ducklake_db\n",
        "        self.path_prefix = os.environ.get(\"TMP\").replace(\"\\\\\",\"/\") if os.name == \"nt\" else \"/tmp\"\n",
        "        self.path = path if path else f\"{self.path_prefix}/dklq_{self.ducklake_db}\"\n",
        "        self.engine =  SpitterDucklakeEngines.get_session_duckdb(self.ducklake_db, self.path)\n",
        "        self.engenieer = SpitterDucklakeEngenieertOperator(self.engine, self.ducklake_db, self.path)\n",
        "        self.analyst = SpitterDucklakeAnalystOperator(self.engine, self.ducklake_db, self.path)\n",
        "\n",
        "        self.dklq = SpitterDucklakeOperator(self.engine, self.ducklake_db)\n",
        "        self.tables = {}\n",
        "        self.op_mode = \"\"\n",
        "        if content:\n",
        "          self.load_bronze(content)\n",
        "\n",
        "    def preview_table(self, table):\n",
        "        with self.engine.connect() as con:\n",
        "          norm_cols = \",\".join([f'\"{col}\" AS {self.dklq.normalize_name(col)}' for col in self.cols])\n",
        "          preview_df = con.exec_driver_sql(f\"\"\"\n",
        "            SELECT {norm_cols} FROM {table} LIMIT 10\n",
        "          \"\"\")\n",
        "          preview_df = pd.DataFrame(preview_df.fetchall(), columns=preview_df.keys())\n",
        "          return preview_df\n",
        "\n",
        "    def run_query(self, query):\n",
        "        with self.engine.connect() as con:\n",
        "          preview_df = con.exec_driver_sql(query)\n",
        "          preview_df = pd.DataFrame(preview_df.fetchall(), columns=preview_df.keys())\n",
        "\n",
        "        return preview_df\n",
        "\n",
        "    def set_primary_key(self, column_name):\n",
        "        if column_name in self.df.columns:\n",
        "            self.primary_key = column_name\n",
        "\n",
        "    def set_table_op_mode(self, op_mode):\n",
        "        self.op_mode = op_mode\n",
        "\n",
        "    def persist_table_on_dklq(self, layer, layer_source):\n",
        "\n",
        "        result = self.dklq.insert_table(f\"{layer_source}.{self.tables[layer_source]}\",\n",
        "                                        self.tables[layer],\n",
        "                                        layer,\n",
        "                                        self.op_mode,\n",
        "                                        self.primary_key)\n",
        "        if not result[0]:\n",
        "          raise Exception(result[1])\n",
        "\n",
        "    def set_list_tables(self, subject):\n",
        "        for layer in [\"tmp\",\"bronze\", \"silver\", \"gold\"]:\n",
        "          prefix = \"\" if layer == \"tmp\" else \"tb_\"\n",
        "          self.tables[layer]= f\"{prefix}{layer}_{subject}\"\n",
        "\n",
        "\n",
        "    def load_bronze(self, file, layer='bronze'):\n",
        "\n",
        "        try:\n",
        "\n",
        "          table= self.dklq.normalize_name(file.name.replace(\"\\\\\", \"/\").split(\"/\")[-1].split(\".\")[0])\n",
        "          self.set_list_tables(table)\n",
        "          with self.engine.connect() as con:\n",
        "            con.exec_driver_sql(f\"\"\"\n",
        "                CREATE TEMPORARY TABLE {self.tables['tmp']} AS\n",
        "                SELECT * FROM read_csv_auto('{file.name}', header=True)\n",
        "            \"\"\")\n",
        "\n",
        "            self.cols = [row[0] for row in con.exec_driver_sql(f\"DESCRIBE {self.tables['tmp']}\").fetchall()]\n",
        "            con.commit()\n",
        "            return True, \"success\"\n",
        "        except Exception as e:\n",
        "          raise (f\"{e} -> {traceback.format_exc()}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SUbTqjEHjbbT"
      },
      "id": "SUbTqjEHjbbT",
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inteface"
      ],
      "metadata": {
        "id": "xXBeupD5fSEh"
      },
      "id": "xXBeupD5fSEh"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "PfmR2fRj_6XA",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 645
        },
        "id": "PfmR2fRj_6XA",
        "outputId": "4b063a92-5fe7-4a3e-c782-1c97e40a4fd8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://a1bc45d75b2c83e383.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://a1bc45d75b2c83e383.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "import gradio as gr\n",
        "\n",
        "def change_tab_bronze():\n",
        "    return 'bronze', 'tmp'\n",
        "\n",
        "def change_tab_silver():\n",
        "    return 'silver',  'engenieer', 'bronze',\n",
        "\n",
        "def change_tab_gold():\n",
        "    return 'gold', 'analyst', 'silver'\n",
        "\n",
        "def set_table_dropdown(spitter_operator, table, table_ref):\n",
        "  table = table if table else table_ref\n",
        "  subject = \"_\".join(table.split(\"_\")[2:])\n",
        "  spitter_operator.set_list_tables(subject)\n",
        "  return spitter_operator\n",
        "\n",
        "def load_tables(spitter_operator, layer):\n",
        "    if not spitter_operator:\n",
        "      spitter_operator = SpitterOperator()\n",
        "\n",
        "    choices = SpitterDucklakeEngines.get_tables(spitter_operator.engine,\n",
        "                                                spitter_operator.ducklake_db,\n",
        "                                                layer)\n",
        "    return (\n",
        "              gr.update(choices=[\"\", *choices],interactive=True,visible=True),\n",
        "              spitter_operator\n",
        "             )\n",
        "\n",
        "\n",
        "def change_tab_queries(spitter_operator):\n",
        "  if not spitter_operator:\n",
        "    spitter_operator = SpitterOperator()\n",
        "  return spitter_operator\n",
        "\n",
        "\n",
        "def init_by_file(file):\n",
        "    spitter_operator = SpitterOperator(content=file)\n",
        "    return spitter_operator\n",
        "\n",
        "def preview_table(spitter_operator, source_layer):\n",
        "    return spitter_operator.preview_table(spitter_operator.tables[source_layer])\n",
        "\n",
        "def run_query(spitter_operator, query):\n",
        "    return spitter_operator.run_query(query), True\n",
        "\n",
        "def set_pk_column(spitter_operator, pk_column):\n",
        "    if spitter_operator is not None:\n",
        "        spitter_operator.set_primary_key(pk_column)\n",
        "    return spitter_operator\n",
        "\n",
        "#button options\n",
        "def set_pk_chk_visibility(spitter_operator, checkbox_value):\n",
        "    if checkbox_value:\n",
        "        return gr.update(interactive=True, visible=True,choices=spitter_operator.cols)\n",
        "    else:\n",
        "        return gr.update(interactive=False, visible=False)\n",
        "\n",
        "def set_op_chk_visibility(spitter_operator, layer):\n",
        "    choices = [\"append\", \"overwrite\"] if layer == \"bronze\" else [\"overwrite\",\"upsert\"]\n",
        "    return gr.update(interactive=True, visible=True, choices= choices)\n",
        "\n",
        "def set_table_op_mode_btn(spitter_operator, op_mode, layer):\n",
        "  spitter_operator.set_table_op_mode(op_mode)\n",
        "  return f\"Commit - table -> {spitter_operator.tables[layer]} | op_mode -> {op_mode}\", True\n",
        "\n",
        "def publish_table(spitter_operator, commit_state, layer, source_layer):\n",
        "  if commit_state:\n",
        "    spitter_operator.persist_table_on_dklq(layer, source_layer)\n",
        "    #spitter_operator.close_connection()\n",
        "    return (\n",
        "        \"sucess\",\n",
        "        None,\n",
        "        pd.DataFrame(),\n",
        "        gr.update(choices=[spitter_operator.tables[layer]],interactive=False, visible=False,value=spitter_operator.tables[layer]),\n",
        "        spitter_operator.tables[layer]\n",
        "        )\n",
        "  else:\n",
        "    return \"Error. Please check your settings!\"\n",
        "\n",
        "\n",
        "\n",
        "def generate_query(spitter_operator, query, layer, source_layer, profile, last_query):\n",
        "  if profile == 'engenieer':\n",
        "    query_gen = spitter_operator.engenieer.generate_sql(\n",
        "                                                        query,\n",
        "                                                        f\"{source_layer}.{spitter_operator.tables[source_layer]}\",\n",
        "                                                        layer,\n",
        "                                                        last_query=last_query\n",
        "                                                        )\n",
        "    return query_gen\n",
        "\n",
        "def update_table_list(spitter_operator):\n",
        "    query = \"\"\"\n",
        "        SELECT database_name, schema_name, table_name\n",
        "        FROM duckdb_tables\n",
        "        WHERE database_name not like '%__ducklake_metadata'\n",
        "        ORDER BY database_name, schema_name, table_name\n",
        "    \"\"\"\n",
        "    with spitter_operator.engine.connect() as con:\n",
        "      result = con.exec_driver_sql(query).fetchall()\n",
        "\n",
        "    if not result:\n",
        "        return \"Nenhuma tabela encontrada.\"\n",
        "\n",
        "    struct = {}\n",
        "    for row in result:\n",
        "        db = row[0]\n",
        "        schema = row[1]\n",
        "        tabela = row[2]\n",
        "        struct.setdefault(db, {}).setdefault(schema, []).append(tabela)\n",
        "\n",
        "    md = \"\"\n",
        "    for db, schemas in struct.items():\n",
        "        md += f\"### 🗄 {db}\\n\"\n",
        "        for schema, tabelas in schemas.items():\n",
        "            md += f\"- **{schema}**\\n\"\n",
        "            for t in tabelas:\n",
        "                md += f\"  - {t}\\n\"\n",
        "    return md\n",
        "\n",
        "with gr.Blocks(title=\"# Arquitetura Medalhão - Data Spitter - CSV - multi Reads\") as spitter_demo:\n",
        "  gr.Markdown(\"# Arquitetura Medalhão (Bronze / Silver / Gold)\")\n",
        "  gr.Markdown(\"## Spitter Data Lakehouse Explorer\")\n",
        "  gr.Markdown(\"## Leia seus dados, configure as operacoes, e maos a obra. Apresentamos suporte a cargas incrementais e de sobrescrita\")\n",
        "  gr.Markdown(\"As tabelas criadas utilizarao o nome do arquivo como referencia\")\n",
        "\n",
        "  st_spitter_operator = gr.State(None)\n",
        "  st_layer = gr.State(\"bronze\")\n",
        "  st_source_layer = gr.State(\"tmp\")\n",
        "  st_profile = gr.State(\"\")\n",
        "  st_s_table_ref = gr.State(\"\")\n",
        "  st_s_table_choices = gr.State([])\n",
        "\n",
        "\n",
        "  with gr.Tabs() as tabs:\n",
        "    #BronzeLayer\n",
        "    with gr.TabItem(\"Bronze Layer\", id=0) as b_tab:\n",
        "      b_tab.select(\n",
        "          change_tab_bronze,\n",
        "          outputs=[st_layer, st_source_layer]\n",
        "      )\n",
        "      gr.Markdown(\"### Upload dos dados brutos\")\n",
        "      st_choices = gr.State([])\n",
        "      st_commit_bronze = gr.State(False)\n",
        "\n",
        "      csv_bronze = gr.File(label=\"Selecione um CSV\",file_count=\"single\", type=\"filepath\")\n",
        "      csv_bronze.upload(init_by_file, inputs=csv_bronze, outputs=[st_spitter_operator])#,st_layer\n",
        "\n",
        "\n",
        "      bronze_btn = gr.Button(\"Preview Bronze\")\n",
        "      bronze_table = gr.DataFrame(label=\"Bronze Data\")\n",
        "      bronze_btn.click(preview_table, inputs=[st_spitter_operator, st_source_layer], outputs=bronze_table)\n",
        "\n",
        "\n",
        "      op_dropdown = gr.Dropdown(label=\"Selecione o modo de operação da tabela (obrigatório)\", choices=[], interactive=False, visible=False)\n",
        "      st_spitter_operator.change(set_op_chk_visibility, inputs=[st_spitter_operator, st_layer],outputs=[op_dropdown])\n",
        "\n",
        "      output_text = gr.Markdown(\"\")\n",
        "      op_dropdown.change(set_table_op_mode_btn, inputs=[st_spitter_operator, op_dropdown, st_layer], outputs=[output_text, st_commit_bronze])\n",
        "\n",
        "      with gr.Row():\n",
        "        alerta_md_component = gr.Markdown(\"\")\n",
        "        publish_bronze_btn = gr.Button(value=f\"Confirmar\", visible=True)\n",
        "        publish_bronze_btn.click(publish_table,\n",
        "                                 inputs=[st_spitter_operator, st_commit_bronze, st_layer, st_source_layer],\n",
        "                                 outputs=[alerta_md_component, csv_bronze, bronze_table, op_dropdown, st_s_table_ref])\n",
        "\n",
        "    #SilverLayer\n",
        "    with gr.TabItem(\"Camada Silver\", id=1) as s_tab:\n",
        "      s_tab.select(\n",
        "            change_tab_silver,\n",
        "            outputs=[st_layer, st_profile, st_source_layer]\n",
        "        )\n",
        "      st_commit_silver =  gr.State(False)\n",
        "\n",
        "\n",
        "      input_dropdown = gr.Dropdown(label=\"Tabela referencia\",\n",
        "                            choices=[],\n",
        "                            visible=False,\n",
        "                            interactive=False\n",
        "                            )\n",
        "\n",
        "      load = gr.Button(\"Ler tabelas consulta\")\n",
        "      load.click(load_tables, inputs=[st_spitter_operator, st_source_layer], outputs=[input_dropdown,st_spitter_operator])\n",
        "      input_dropdown.change(set_table_dropdown, inputs=[st_spitter_operator,input_dropdown, st_s_table_ref], outputs=st_s_table_ref)\n",
        "\n",
        "\n",
        "      input_s = gr.Textbox(label=\"Por favor, insira as transformações necessárias\",\n",
        "                            lines=2,\n",
        "                            max_lines=10,\n",
        "                            placeholder=\"Escreva aqui...\",\n",
        "                            interactive=True\n",
        "                          )\n",
        "      with gr.Row():\n",
        "        submit_gen_q = gr.Button(\"Gerar consulta\")\n",
        "        test_q = gr.Button(\"Testar consulta\")\n",
        "\n",
        "      output_s_query = gr.Textbox(label=\"Query gerada\",\n",
        "                                  lines=2,\n",
        "                                  max_lines=10,\n",
        "                                  placeholder=\"Sua query sera gerada aqui, voce pode alterar e testar sua consulta...\",\n",
        "                                  interactive=True\n",
        "                                )\n",
        "\n",
        "      test_table = gr.DataFrame(label=\"Saida\")\n",
        "\n",
        "      submit_gen_q.click(generate_query, inputs=[st_spitter_operator, input_s, st_layer, st_source_layer, st_profile, output_s_query], outputs=output_s_query)\n",
        "      #input_s.change(lambda x: x, inputs=input_s, outputs=output_s_query)\n",
        "      test_q.click(run_query, inputs=[st_spitter_operator, output_s_query], outputs=[test_table,st_commit_silver])\n",
        "\n",
        "      pk_checkbox = gr.Checkbox(label=\"A tabela possui uma chave primária?\", value=False)\n",
        "      pk_dropdown = gr.Dropdown(label=\"Selecione a chave\", choices=[], interactive=False, visible=False)\n",
        "      pk_checkbox.change(set_pk_chk_visibility, inputs=[st_spitter_operator, pk_checkbox], outputs=pk_dropdown)\n",
        "      pk_dropdown.change(set_pk_column, inputs=[st_spitter_operator, pk_dropdown], outputs=st_spitter_operator)\n",
        "      with gr.Row():\n",
        "        publish_silver_btn = gr.Button(value=f\"Confirmar\", visible=True)\n",
        "        publish_silver_btn.click(publish_table,\n",
        "                                 inputs=[st_spitter_operator, st_commit_silver, st_layer, st_source_layer],\n",
        "                                 outputs=[st_s_table_ref])\n",
        "\n",
        "    with gr.TabItem(\"Explorer\", id=4) as ex_tab:\n",
        "      ex_tab.select(\n",
        "                change_tab_queries,\n",
        "                inputs=[st_spitter_operator],\n",
        "                outputs=[st_spitter_operator]\n",
        "            )\n",
        "      st_result = gr.State(False)\n",
        "      with gr.Row():\n",
        "        with gr.Column(scale=1):\n",
        "            gr.Markdown(\"Databases e Tabelas\")\n",
        "            update = gr.Button(\"Atualizar\")\n",
        "            output = gr.Markdown()\n",
        "            update.click(update_table_list, inputs=st_spitter_operator,  outputs=output)\n",
        "\n",
        "        with gr.Column(scale=2):\n",
        "            gr.Markdown(\"Interface de Queries SQL\")\n",
        "            ex_query = gr.Textbox(\n",
        "                            label=\"Escreva sua Query SQL\",\n",
        "                            placeholder=\"Ex: SELECT * FROM clientes WHERE db.schema.idade > 25\",\n",
        "                            lines=5,\n",
        "                            elem_id=\"query-box\"\n",
        "                          )\n",
        "            run = gr.Button(\"Executar Query\")\n",
        "            output = gr.DataFrame(label=\"Resultado\", interactive=False)\n",
        "            run.click(run_query, inputs=[st_spitter_operator, ex_query], outputs=[output,st_result])\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    spitter_demo.launch(debug=True)\n",
        "#spitter_demo.launch(debug=True)\n",
        "#spitter_demo.queue(show_error=True)\n",
        "#spitter_demo.launch(share=True)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import duckdb\n",
        "import gradio as gr\n",
        "\n",
        "# Conexão DuckDB\n",
        "\n",
        "# Função para gerar hierarquia\n",
        "def listar_hierarquia():\n",
        "    spitter_operator = SpitterOperator()\n",
        "    query = \"\"\"\n",
        "        SELECT database_name, schema_name, table_name\n",
        "        FROM duckdb_tables\n",
        "        ORDER BY database_name, schema_name, table_name\n",
        "    \"\"\"\n",
        "    with spitter_operator.engine.connect() as con:\n",
        "      df = con.exec_driver_sql(query)\n",
        "      df = pd.DataFrame(df.fetchall(), columns=df.keys())\n",
        "      if df.empty:\n",
        "          return \"Nenhuma tabela encontrada.\"\n",
        "\n",
        "    # Monta hierarquia em Markdown\n",
        "    hierarquia = {}\n",
        "    for _, row in df.iterrows():\n",
        "        db = row\n",
        "        schema = row.schema_name\n",
        "        tabela = row.table_name\n",
        "        hierarquia.setdefault(db, {}).setdefault(schema, []).append(tabela)\n",
        "\n",
        "    # Converte para Markdown\n",
        "    md = \"\"\n",
        "    for db, schemas in hierarquia.items():\n",
        "        md += f\"### 🗄 {db}\\n\"\n",
        "        for schema, tabelas in schemas.items():\n",
        "            md += f\"- **{schema}**\\n\"\n",
        "            for t in tabelas:\n",
        "                md += f\"  - {t}\\n\"\n",
        "    return md\n",
        "\n",
        "# --- Interface Gradio ---\n",
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"## 🦆 DuckDB Explorer (Hierarquia)\")\n",
        "    btn = gr.Button(\"🔄 Atualizar hierarquia\")\n",
        "    saida = gr.Markdown()\n",
        "    btn.click(listar_hierarquia, outputs=saida)\n",
        "\n",
        "demo.launch(debug=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 697
        },
        "id": "t9TRbn8k3HSu",
        "outputId": "3d9bc86b-71ab-47d2-b4ef-2d197d5463d6"
      },
      "id": "t9TRbn8k3HSu",
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://aa763aa3633f5263ef.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://aa763aa3633f5263ef.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Databases anexados: ['memory', 'spitter_ducklake']\n",
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7863 <> https://aa763aa3633f5263ef.gradio.live\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jooX2Mzr3Zbj"
      },
      "id": "jooX2Mzr3Zbj",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [],
      "dockerImageVersionId": 31153,
      "isGpuEnabled": false,
      "isInternetEnabled": false,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.10"
    },
    "papermill": {
      "default_parameters": {},
      "duration": 5.226134,
      "end_time": "2025-10-24T20:20:57.625124",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2025-10-24T20:20:52.398990",
      "version": "2.6.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}