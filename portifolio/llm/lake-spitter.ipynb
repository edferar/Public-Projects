{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "12188207",
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "execution": {
          "iopub.execute_input": "2025-10-24T20:20:57.294238Z",
          "iopub.status.busy": "2025-10-24T20:20:57.293457Z",
          "iopub.status.idle": "2025-10-24T20:20:57.302473Z",
          "shell.execute_reply": "2025-10-24T20:20:57.301296Z"
        },
        "papermill": {
          "duration": 0.013511,
          "end_time": "2025-10-24T20:20:57.303990",
          "exception": false,
          "start_time": "2025-10-24T20:20:57.290479",
          "status": "completed"
        },
        "tags": [],
        "id": "12188207",
        "outputId": "b7c5989f-04c7-4c50-9944-e9a79d78347b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Um cuspidor esta nascendo!\n"
          ]
        }
      ],
      "source": [
        "print(\"Um cuspidor esta nascendo!\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CRroonA0A0WK"
      },
      "id": "CRroonA0A0WK",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gradio duckdb pandas --quiet\n"
      ],
      "metadata": {
        "id": "nilEBfU7_3ao"
      },
      "id": "nilEBfU7_3ao",
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#csv operations\n",
        "import chardet\n",
        "import pandas as pd\n",
        "import csv\n",
        "\n",
        "\n",
        "def get_file_eoptions(arquivo):\n",
        "    options = {}\n",
        "    sample = f.read(2048)  # lê uma amostra do arquivo\n",
        "    sniffer = csv.Sniffer()\n",
        "    dialect = sniffer.sniff(sample)\n",
        "    options[\"delimiter\"] = dialect.delimiter\n",
        "    options[\"encoding\"] = chardet.detect(raw_data)['encoding']\n",
        "    return options\n",
        "\n",
        "\n",
        "def carregar_bronze(arquivo):\n",
        "    if arquivo is None:\n",
        "        return \"Envie um arquivo CSV.\"\n",
        "    df = pd.read_csv(arquivo.name,delimiter=op[\"encoding\"],encoding=op[\"encoding\"])\n",
        "    duckdb.register(\"bronze\", df)\n",
        "    return df.head(5)"
      ],
      "metadata": {
        "id": "-8fKAy_MFPm9"
      },
      "id": "-8fKAy_MFPm9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import pandas as pd\n",
        "import csv\n",
        "import duckdb\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "with gr.Blocks(title=\"Arquitetura Medalhão - Data Spitter - CSV - multi Reads\") as demo:\n",
        "    gr.Markdown(\"#Arquitetura Medalhão (Bronze / Silver / Gold)\")\n",
        "    gr.Markdown(\"Leia seus dados, configure as operacoes, e maos a obra. Apresentamos suporte a cargas incrementais e de sobrescrita\")\n",
        "\n",
        "\n",
        "    # Camada Bronze\n",
        "    with gr.Tab(\"Camada Bronze\"):\n",
        "        gr.Markdown(\"### Upload dos dados brutos\")\n",
        "        arquivo_bronze = gr.File(label=\"Selecione um CSV\")\n",
        "        bronze_tabela = gr.DataFrame(label=\"Prévia dos dados Bronze\")\n",
        "        arquivo_bronze.upload(carregar_bronze, inputs=arquivo_bronze, outputs=bronze_tabela)\n",
        "\n",
        "    # # Camada Silver\n",
        "    # with gr.Tab(\"Camada Silver\"):\n",
        "    #     gr.Markdown(\"### Limpeza e padronização dos dados\")\n",
        "    #     botao_silver = gr.Button(\"Transformar Bronze → Silver\")\n",
        "    #     silver_tabela = gr.DataFrame(label=\"Prévia dos dados Silver\")\n",
        "    #     botao_silver.click(transformar_para_silver, outputs=silver_tabela)\n",
        "\n",
        "    # # Camada Gold\n",
        "    # with gr.Tab(\"Camada Gold\"):\n",
        "    #     gr.Markdown(\"### Agregações e métricas finais\")\n",
        "    #     botao_gold = gr.Button(\"Transformar Silver → Gold\")\n",
        "    #     gold_tabela = gr.DataFrame(label=\"Tabela final Gold\")\n",
        "    #     botao_gold.click(transformar_para_gold, outputs=gold_tabela)\n",
        "\n",
        "demo.launch(inline=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        },
        "id": "PfmR2fRj_6XA",
        "outputId": "88c21195-ae35-4727-a100-0cfe2b28644d"
      },
      "id": "PfmR2fRj_6XA",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://972b3197a0e2818b13.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://972b3197a0e2818b13.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    }
  ],
  "metadata": {
    "kaggle": {
      "accelerator": "none",
      "dataSources": [],
      "dockerImageVersionId": 31153,
      "isGpuEnabled": false,
      "isInternetEnabled": false,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    },
    "papermill": {
      "default_parameters": {},
      "duration": 5.226134,
      "end_time": "2025-10-24T20:20:57.625124",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2025-10-24T20:20:52.398990",
      "version": "2.6.0"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}