{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "12188207",
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "execution": {
          "iopub.execute_input": "2025-10-24T20:20:57.294238Z",
          "iopub.status.busy": "2025-10-24T20:20:57.293457Z",
          "iopub.status.idle": "2025-10-24T20:20:57.302473Z",
          "shell.execute_reply": "2025-10-24T20:20:57.301296Z"
        },
        "papermill": {
          "duration": 0.013511,
          "end_time": "2025-10-24T20:20:57.303990",
          "exception": false,
          "start_time": "2025-10-24T20:20:57.290479",
          "status": "completed"
        },
        "tags": [],
        "id": "12188207",
        "outputId": "4dadd2bb-47e0-486d-a021-081f5f4334c4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Um cuspidor esta nascendo!\n"
          ]
        }
      ],
      "source": [
        "print(\"Um cuspidor esta nascendo!\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ.get(\"TMP\")"
      ],
      "metadata": {
        "id": "9uIMq2xKCQsd"
      },
      "id": "9uIMq2xKCQsd",
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gradio duckdb pandas unidecode --quiet\n"
      ],
      "metadata": {
        "id": "nilEBfU7_3ao",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fbc0b6de-57cb-4943-849c-ef2ad0d1b05f"
      },
      "id": "nilEBfU7_3ao",
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/235.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m235.5/235.8 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.8/235.8 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "mp1gCpwvlQ5m"
      },
      "id": "mp1gCpwvlQ5m"
    },
    {
      "cell_type": "code",
      "source": [
        "from unidecode import unidecode\n",
        "import traceback\n",
        "import os\n",
        "\n",
        "import re\n",
        "\n",
        "class SpitterDucklakeOperator():\n",
        "    def __init__(self,con,  path=None):\n",
        "\n",
        "      self.ducklake_db = \"spitter_ducklake\"\n",
        "      self.path_prefix = os.environ.get(\"TMP\").replace(\"\\\\\",\"/\") if os.name == \"nt\" else \"/tmp\"\n",
        "      self.path = path if path else f\"{self.path_prefix}/dklq_{self.ducklake_db}\"\n",
        "      self.con = con\n",
        "      self.init_ducklake()\n",
        "\n",
        "\n",
        "    def init_ducklake(self):\n",
        "      try:\n",
        "        #con = duckdb.connect(database=':memory:')\n",
        "        self.con.execute(\"INSTALL ducklake;\")\n",
        "        self.con.execute(f\"DETACH DATABASE IF EXISTS {self.ducklake_db};\")\n",
        "        self.con.execute(f\"ATTACH 'ducklake:metadata.ducklake' AS {self.ducklake_db} (DATA_PATH '{self.path}');\")\n",
        "        #return con\n",
        "      except Exception as e:\n",
        "        raise e\n",
        "\n",
        "    def table_exist(self, table):\n",
        "      try:\n",
        "        self.con.execute(f\"SELECT * FROM {table} LIMIT 0\")\n",
        "        return True\n",
        "      except Exception as e:\n",
        "        return False\n",
        "\n",
        "    def normalize_column_name(self, col):\n",
        "      col = unidecode(col).lower().strip()\n",
        "      col = re.sub(r'[^a-z0-9_]', '_', col)\n",
        "      col = re.sub(r'_+', '_', col)\n",
        "      return col.strip('_')\n",
        "\n",
        "\n",
        "    def create_or_replace_table(self, source_table_name, output_table_name, layer, primary_key=False):\n",
        "      try:\n",
        "        self.con.execute(f\"CREATE SCHEMA IF NOT EXISTS {self.ducklake_db}.{layer}\")\n",
        "\n",
        "        instruction_sql = ','.join([\"{0} {1} {2}\".format(\n",
        "                                                          self.normalize_column_name(row[0]),\n",
        "                                                          row[1],\n",
        "                                                          \"\" if row[0] != primary_key else 'PRIMARY KEY'\n",
        "                                                        ) for row in self.con.execute(f\"DESCRIBE FROM {source_table_name}\").fetchall()\n",
        "                                  ]\n",
        "                                    )\n",
        "\n",
        "        self.con.execute(f\"\"\"CREATE OR REPLACE TABLE {self.ducklake_db}.{layer}.{output_table_name} ({instruction_sql})\"\"\")\n",
        "\n",
        "        return True, \"success\"\n",
        "      except Exception as e:\n",
        "        return False, f\"{e} -> {traceback.format_exc()}\"\n",
        "\n",
        "    def insert_table(self, source_table_name, output_table_name, layer,op_mode, primary_key=False):\n",
        "      try:\n",
        "        if not self.table_exist(f\"{self.ducklake_db}.{layer}.{output_table_name}\") or op_mode == \"overwrite\":\n",
        "            self.create_or_replace_table(source_table_name, output_table_name, layer, primary_key)\n",
        "\n",
        "        if primary_key:\n",
        "          self.con.execute(f\"INSERT OR REPLACE INTO {self.ducklake_db}.{layer}.{output_table_name} SELECT * FROM {source_table_name}\")\n",
        "        else:\n",
        "          self.con.execute(f\"INSERT INTO {self.ducklake_db}.{layer}.{output_table_name} SELECT * FROM {source_table_name}\")\n",
        "\n",
        "        return True, \"success\"\n",
        "      except Exception as e:\n",
        "        return False, f\"{e} -> {traceback.format_exc()}\"\n",
        "\n"
      ],
      "metadata": {
        "id": "YUJttku7PY-t"
      },
      "id": "YUJttku7PY-t",
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#csv operations\n",
        "import chardet\n",
        "import duckdb\n",
        "import pandas as pd\n",
        "import traceback\n",
        "\n",
        "class SpitterOperator():\n",
        "    def __init__(self, file):\n",
        "        self.df = pd.DataFrame()\n",
        "        self.primary_key = \"\"\n",
        "        self.cols = []\n",
        "        self.con = duckdb.connect(database=':memory:')\n",
        "        self.dklq = SpitterDucklakeOperator(self.con)\n",
        "        self.table_name = \"\"\n",
        "        self.op_mode = \"\"\n",
        "        if file is not None:\n",
        "            self.load_bronze(file)\n",
        "        else:\n",
        "            return \"Envie um file CSV.\"\n",
        "\n",
        "    def preview_bronze(self):\n",
        "        norm_cols = \",\".join([f'\"{col}\" AS {self.dklq.normalize_column_name(col)}' for col in self.cols])\n",
        "        preview_df = self.con.execute(f\"\"\"\n",
        "          SELECT {norm_cols} FROM tmp_{self.table_name} LIMIT 10\n",
        "        \"\"\").fetchdf()\n",
        "        return preview_df\n",
        "\n",
        "    def set_primary_key(self, column_name):\n",
        "        if column_name in self.df.columns:\n",
        "            self.primary_key = column_name\n",
        "\n",
        "    def set_table_op_mode(self, op_mode):\n",
        "        self.op_mode = op_mode\n",
        "\n",
        "    def persist_table_on_dklq(self, layer):\n",
        "        result = self.dklq.insert_table(f\"tmp_{self.table_name}\", f\"tb_{layer}_{self.table_name}\", layer, self.op_mode, self.primary_key)\n",
        "        if not result[0]:\n",
        "          raise Exception(result[1])\n",
        "\n",
        "\n",
        "    def load_bronze(self,file):\n",
        "\n",
        "        try:\n",
        "          self.table_name = file.name.replace(\"\\\\\", \"/\").split(\"/\")[-1].split(\".\")[0]\n",
        "          self.con.execute(f\"\"\"\n",
        "              CREATE TEMPORARY TABLE tmp_{self.table_name} AS\n",
        "              SELECT * FROM read_csv_auto('{file.name}', header=True)\n",
        "          \"\"\")\n",
        "          self.cols = [row[0] for row in self.con.execute(f\"DESCRIBE tmp_{self.table_name}\").fetchall()]\n",
        "        except Exception as e:\n",
        "          raise (f\"{e} -> {traceback.format_exc()}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "-8fKAy_MFPm9"
      },
      "id": "-8fKAy_MFPm9",
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "\n",
        "def init_file_operator(file):\n",
        "    spitter_operator = SpitterOperator(file)\n",
        "    return spitter_operator, \"bronze\"\n",
        "\n",
        "def preview_bronze(spitter_operator):\n",
        "    return spitter_operator.preview_bronze()\n",
        "\n",
        "def set_pk_column(spitter_operator, pk_column):\n",
        "    if spitter_operator is not None:\n",
        "        spitter_operator.set_primary_key(pk_column)\n",
        "    return spitter_operator\n",
        "\n",
        "#button options\n",
        "def set_pk_chk_visibility(spitter_operator, checkbox_value):\n",
        "    if checkbox_value:\n",
        "        return gr.update(interactive=True, visible=True,choices=spitter_operator.cols)\n",
        "    else:\n",
        "        return gr.update(interactive=False, visible=False)\n",
        "\n",
        "def set_op_chk_visibility(spitter_operator, layer):\n",
        "    choices = [\"append\", \"overwrite\"] if layer == \"bronze\" else [\"overwrite\",\"upsert\"]\n",
        "    return gr.update(interactive=True, visible=True, choices= choices)\n",
        "\n",
        "\n",
        "def set_table_op_mode_btn(spitter_operator, op_mode):\n",
        "  spitter_operator.set_table_op_mode(op_mode)\n",
        "  return f\"Commit - table -> {spitter_operator.table_name} | op_mode -> {op_mode}\", True\n",
        "\n",
        "def publish_bronze_table(spitter_operator, commit_state, layer):\n",
        "  if commit_state:\n",
        "    spitter_operator.persist_table_on_dklq(layer)\n",
        "    return \"sucess\"\n",
        "  else:\n",
        "    return \"Error. Please check your settings!\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "with gr.Blocks(title=\"# Arquitetura Medalhão - Data Spitter - CSV - multi Reads\") as demo:\n",
        "    gr.Markdown(\"# Arquitetura Medalhão (Bronze / Silver / Gold)\")\n",
        "    gr.Markdown(\"## Spitter Data Lakehouse Explorer\")\n",
        "    gr.Markdown(\"## Leia seus dados, configure as operacoes, e maos a obra. Apresentamos suporte a cargas incrementais e de sobrescrita\")\n",
        "    gr.Markdown(\"As tabelas criadas utilizarao o nome do arquivo como referencia\")\n",
        "    st_spitter_operator = gr.State(None)\n",
        "    st_layer = gr.State(\"\")\n",
        "\n",
        "    #BronzeLayer\n",
        "    with gr.Tab(\"Bronze Layer\"):\n",
        "        gr.Markdown(\"### Upload dos dados brutos\")\n",
        "        st_choices = gr.State([])\n",
        "        st_commit_bronze = gr.State(False)\n",
        "\n",
        "        csv_bronze = gr.File(label=\"Selecione um CSV\",file_count=\"single\", type=\"filepath\")\n",
        "        csv_bronze.upload(init_file_operator, inputs=csv_bronze, outputs=[st_spitter_operator,st_layer])\n",
        "\n",
        "        gr.Markdown(\"### Preview dos dados brutos\")\n",
        "        bronze_btn = gr.Button(\"Preview Bronze\")\n",
        "        bronze_table = gr.DataFrame(label=\"Bronze Data\")\n",
        "        bronze_btn.click(preview_bronze, inputs=st_spitter_operator, outputs=bronze_table)\n",
        "\n",
        "        gr.Markdown(\"### Limpeza dos dados brutos\")\n",
        "\n",
        "\n",
        "        op_dropdown = gr.Dropdown(label=\"Select the table operaration mode (required)\", choices=[], interactive=False, visible=False)\n",
        "        st_spitter_operator.change(set_op_chk_visibility,inputs=[st_spitter_operator, st_layer],outputs=op_dropdown)\n",
        "\n",
        "        output_text = gr.Markdown(\"\")\n",
        "        op_dropdown.change(set_table_op_mode_btn, inputs=[st_spitter_operator, op_dropdown], outputs=[output_text, st_commit_bronze])\n",
        "\n",
        "        alerta_md_component = gr.Markdown(\"\")\n",
        "        publish_bronze_btn = gr.Button(value=f\"Commit\", visible=True)\n",
        "        publish_bronze_btn.click(publish_bronze_table, inputs=[st_spitter_operator, st_commit_bronze, st_layer], outputs=alerta_md_component)\n",
        "    #SilverLayer\n",
        "    with gr.Tab(\"Camada Silver\"):\n",
        "        gr.Markdown(\"### Limpeza dos dados brutos\")\n",
        "        pk_checkbox = gr.Checkbox(label=\"Does the table have a primary key?\", value=False)\n",
        "        pk_dropdown = gr.Dropdown(label=\"Select the primary key\", choices=[], interactive=False, visible=False)\n",
        "        pk_checkbox.change(set_pk_chk_visibility, inputs=[st_spitter_operator, pk_checkbox], outputs=pk_dropdown)\n",
        "        pk_dropdown.change(set_pk_column, inputs=[st_spitter_operator, pk_dropdown], outputs=st_spitter_operator)\n",
        "\n",
        "\n",
        "\n",
        "demo.launch(debug=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "PfmR2fRj_6XA",
        "outputId": "a44ddc13-9e61-48e9-f81d-ac5dfb685dde"
      },
      "id": "PfmR2fRj_6XA",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://fec2d183189a152984.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://fec2d183189a152984.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:    Exception in ASGI application\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/uvicorn/protocols/http/h11_impl.py\", line 403, in run_asgi\n",
            "    result = await app(  # type: ignore[func-returns-value]\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/uvicorn/middleware/proxy_headers.py\", line 60, in __call__\n",
            "    return await self.app(scope, receive, send)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/fastapi/applications.py\", line 1133, in __call__\n",
            "    await super().__call__(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/applications.py\", line 113, in __call__\n",
            "    await self.middleware_stack(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/middleware/errors.py\", line 186, in __call__\n",
            "    raise exc\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/middleware/errors.py\", line 164, in __call__\n",
            "    await self.app(scope, receive, _send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/gradio/brotli_middleware.py\", line 74, in __call__\n",
            "    return await self.app(scope, receive, send)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/gradio/route_utils.py\", line 882, in __call__\n",
            "    await self.app(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/middleware/exceptions.py\", line 63, in __call__\n",
            "    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/_exception_handler.py\", line 53, in wrapped_app\n",
            "    raise exc\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/_exception_handler.py\", line 42, in wrapped_app\n",
            "    await app(scope, receive, sender)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/fastapi/middleware/asyncexitstack.py\", line 18, in __call__\n",
            "    await self.app(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/routing.py\", line 716, in __call__\n",
            "    await self.middleware_stack(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/routing.py\", line 736, in app\n",
            "    await route.handle(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/routing.py\", line 290, in handle\n",
            "    await self.app(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/fastapi/routing.py\", line 123, in app\n",
            "    await wrap_app_handling_exceptions(app, request)(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/_exception_handler.py\", line 53, in wrapped_app\n",
            "    raise exc\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/_exception_handler.py\", line 42, in wrapped_app\n",
            "    await app(scope, receive, sender)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/fastapi/routing.py\", line 109, in app\n",
            "    response = await f(request)\n",
            "               ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/fastapi/routing.py\", line 389, in app\n",
            "    raw_response = await run_endpoint_function(\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/fastapi/routing.py\", line 288, in run_endpoint_function\n",
            "    return await dependant.call(**values)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/gradio/routes.py\", line 1671, in get_upload_progress\n",
            "    await asyncio.wait_for(\n",
            "  File \"/usr/lib/python3.12/asyncio/tasks.py\", line 520, in wait_for\n",
            "    return await fut\n",
            "           ^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/gradio/route_utils.py\", line 528, in is_tracked\n",
            "    return await self._signals[upload_id].wait()\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/asyncio/locks.py\", line 209, in wait\n",
            "    fut = self._get_loop().create_future()\n",
            "          ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/asyncio/mixins.py\", line 20, in _get_loop\n",
            "    raise RuntimeError(f'{self!r} is bound to a different event loop')\n",
            "RuntimeError: <asyncio.locks.Event object at 0x7d11d03d35f0 [unset]> is bound to a different event loop\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kaggle": {
      "accelerator": "none",
      "dataSources": [],
      "dockerImageVersionId": 31153,
      "isGpuEnabled": false,
      "isInternetEnabled": false,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    },
    "papermill": {
      "default_parameters": {},
      "duration": 5.226134,
      "end_time": "2025-10-24T20:20:57.625124",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2025-10-24T20:20:52.398990",
      "version": "2.6.0"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}